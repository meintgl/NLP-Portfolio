{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**WordNet**"
      ],
      "metadata": {
        "id": "sItgsP2mzs11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordNet**\n",
        "\n",
        "WordNet is a hierarchal collection that contains the following: nouns, verbs, adjectives, and adverbs. It al contains glosses, which are short definitions, synsets, which are synonym sets, use examples, and relations to other words.\n",
        "\n",
        "This project aims to demonstrate the use of WordNet and SentiWordNet.\n",
        "\n",
        "Author: Meinhard Benedict Capucao"
      ],
      "metadata": {
        "id": "u3LIaEh-zxPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2BNc4yfzxCl",
        "outputId": "057fd4e4-0e2a-47fa-9d23-fdaa11af9df3"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a **Sysnet**?\n",
        "\n",
        "A sysnet is a hierarchical grouping of words with similar meaning. They are divided into:\n",
        "\n",
        "*   Hypernyms: The higher word, where similar words fall under.\n",
        "*   Hyponyms: The lower word, which falls under the category of a broader word.\n",
        "\n",
        "*   Meronyms: A word that is part of another; elements that combine to make a whole.\n",
        "*   Holoynms: A word that is the whole of other parts, opposite of meronyms.\n",
        "\n",
        "*   Tropoynms: A word that is a more specific action of another word.\n",
        "\n",
        "**Noun Sysnet Exploration**\n",
        "\n",
        "First, we will find the sysnets for a noun. Let's use 'drink'.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KQ7YL_Lk6qKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sysnets for 'drink', and output them.\n",
        "wn.synsets('drink')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70njCPp-8Tvg",
        "outputId": "2aae7d30-8851-45b4-f1dd-69dcd01a3236"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('drink.n.01'),\n",
              " Synset('drink.n.02'),\n",
              " Synset('beverage.n.01'),\n",
              " Synset('drink.n.04'),\n",
              " Synset('swallow.n.02'),\n",
              " Synset('drink.v.01'),\n",
              " Synset('drink.v.02'),\n",
              " Synset('toast.v.02'),\n",
              " Synset('drink_in.v.01'),\n",
              " Synset('drink.v.05')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's select one of the sysnets. In this demonstration, we'll select **'beverage.n.01'**, since it is also a noun. We will get the definition, usage example, and lemmas for beverage.n.01:\n",
        "\n",
        "*  ** Definition: **any liquid suitable for drinking\n",
        "*  ** Usage examples:** ['may I take your beverage order?']\n",
        "*   **Examples:** [Lemma('beverage.n.01.beverage'), Lemma('beverage.n.01.drink'), Lemma('beverage.n.01.drinkable'), Lemma('beverage.n.01.potable')]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVskQIcv9ujY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('beverage.n.01').definition() + '\\n' + str(wn.synset('beverage.n.01').examples()) + '\\n' + str(wn.synset('beverage.n.01').lemmas()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovvBX-3-4F4",
        "outputId": "d0264aec-5659-4c1f-fac1-b7a9306cdd88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "any liquid suitable for drinking\n",
            "['may I take your beverage order?']\n",
            "[Lemma('beverage.n.01.beverage'), Lemma('beverage.n.01.drink'), Lemma('beverage.n.01.drinkable'), Lemma('beverage.n.01.potable')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's walk up the hierarchy for the noun synset beverage.\n",
        "\n",
        "WordNet is hierarchically organized for nouns with entity at the top. Then, depending on the sysnet, it becomes more specific. The top of the beverage sysnet is entity, as all knowns. However, above beverage is food, substance,  matter, physical entity, then entity."
      ],
      "metadata": {
        "id": "c2Z_xiXhBVDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beverage = wn.synset('beverage.n.01')\n",
        "bev = beverage.hypernyms()[0]\n",
        "top = wn.synset('entity.n.01')\n",
        "while bev:\n",
        "    print(bev)\n",
        "    if bev == top:\n",
        "        break\n",
        "    if bev.hypernyms():\n",
        "        bev = bev.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXBixhlmC0eB",
        "outputId": "2164167f-7099-48dc-843d-bdd59a939823"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('food.n.01')\n",
            "Synset('substance.n.07')\n",
            "Synset('matter.n.03')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will output the **hypernyms**, **hyponyms**, **meronyms**,\n",
        "**holonyms**, and **antonyms**. Looks like beverage has a few hypernyms, and a lot of hyponyms, which makes sense since there are many types of beverages."
      ],
      "metadata": {
        "id": "b_gPCfX1AZy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('hypernyms: ', beverage.hypernyms())\n",
        "print('hyponyms: ', beverage.hyponyms())\n",
        "print('meronyms: ', beverage.part_meronyms())\n",
        "print('holonyms: ', beverage.part_holonyms())\n",
        "print('antonyms: ', beverage.lemmas()[0].antonyms())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCsAqp6_A9or",
        "outputId": "05ddc97d-172d-4ed4-8e34-0aa5d1e7d106"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypernyms:  [Synset('food.n.01'), Synset('liquid.n.01')]\n",
            "hyponyms:  [Synset('alcohol.n.01'), Synset('cider.n.01'), Synset('cocoa.n.01'), Synset('coffee.n.01'), Synset('cooler.n.02'), Synset('drinking_water.n.01'), Synset('fizz.n.01'), Synset('fruit_drink.n.01'), Synset('fruit_juice.n.01'), Synset('ginger_beer.n.01'), Synset('hydromel.n.01'), Synset('mate.n.09'), Synset('milk.n.01'), Synset('mixer.n.02'), Synset('near_beer.n.01'), Synset('oenomel.n.01'), Synset('potion.n.01'), Synset('refresher.n.02'), Synset('smoothie.n.02'), Synset('soft_drink.n.01'), Synset('tea-like_drink.n.01'), Synset('tea.n.01'), Synset('wish-wash.n.01')]\n",
            "meronyms:  []\n",
            "holonyms:  []\n",
            "antonyms:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verb Sysnet Exploration**\n",
        "\n",
        "First, we will find the sysnets for a verb. Let's use 'run' and the first verb that appears **('run.v.01').**"
      ],
      "metadata": {
        "id": "0LiU5P9nIjKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sysnets for 'drink', and output them.\n",
        "wn.synsets('run')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_N3ZrU5I0_L",
        "outputId": "93e54758-0f48-477f-b24c-918d5bfa3fd2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('run.n.01'),\n",
              " Synset('test.n.05'),\n",
              " Synset('footrace.n.01'),\n",
              " Synset('streak.n.01'),\n",
              " Synset('run.n.05'),\n",
              " Synset('run.n.06'),\n",
              " Synset('run.n.07'),\n",
              " Synset('run.n.08'),\n",
              " Synset('run.n.09'),\n",
              " Synset('run.n.10'),\n",
              " Synset('rivulet.n.01'),\n",
              " Synset('political_campaign.n.01'),\n",
              " Synset('run.n.13'),\n",
              " Synset('discharge.n.06'),\n",
              " Synset('run.n.15'),\n",
              " Synset('run.n.16'),\n",
              " Synset('run.v.01'),\n",
              " Synset('scat.v.01'),\n",
              " Synset('run.v.03'),\n",
              " Synset('operate.v.01'),\n",
              " Synset('run.v.05'),\n",
              " Synset('run.v.06'),\n",
              " Synset('function.v.01'),\n",
              " Synset('range.v.01'),\n",
              " Synset('campaign.v.01'),\n",
              " Synset('play.v.18'),\n",
              " Synset('run.v.11'),\n",
              " Synset('tend.v.01'),\n",
              " Synset('run.v.13'),\n",
              " Synset('run.v.14'),\n",
              " Synset('run.v.15'),\n",
              " Synset('run.v.16'),\n",
              " Synset('prevail.v.03'),\n",
              " Synset('run.v.18'),\n",
              " Synset('run.v.19'),\n",
              " Synset('carry.v.15'),\n",
              " Synset('run.v.21'),\n",
              " Synset('guide.v.05'),\n",
              " Synset('run.v.23'),\n",
              " Synset('run.v.24'),\n",
              " Synset('run.v.25'),\n",
              " Synset('run.v.26'),\n",
              " Synset('run.v.27'),\n",
              " Synset('run.v.28'),\n",
              " Synset('run.v.29'),\n",
              " Synset('run.v.30'),\n",
              " Synset('run.v.31'),\n",
              " Synset('run.v.32'),\n",
              " Synset('run.v.33'),\n",
              " Synset('run.v.34'),\n",
              " Synset('ply.v.03'),\n",
              " Synset('hunt.v.01'),\n",
              " Synset('race.v.02'),\n",
              " Synset('move.v.13'),\n",
              " Synset('melt.v.01'),\n",
              " Synset('ladder.v.01'),\n",
              " Synset('run.v.41')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's select one of the sysnets. In this demonstration, we'll select **''run.v.01''**, since it is the first verb. We will get the definition, usage example, and lemmas for run.v.01:\n",
        "\n",
        "* **Definition:** move fast by using one's feet, with one foot off the ground at any given time\n",
        "*  **Usage examples:** [\"Don't run--you'll be out of breath\", 'The children ran to the store']\n",
        "*   **Examples:** [Lemma('run.v.01.run')]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9kwo2JJ0JIci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('run.v.01').definition() + '\\n' + str(wn.synset('run.v.01').examples()) + '\\n' + str(wn.synset('run.v.01').lemmas()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8CRM_JxJX1E",
        "outputId": "bfa43cd4-b297-4369-dcea-d9efbbc6d6c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "move fast by using one's feet, with one foot off the ground at any given time\n",
            "[\"Don't run--you'll be out of breath\", 'The children ran to the store']\n",
            "[Lemma('run.v.01.run')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's walk up the hierarchy for the verb synset run.\n",
        "\n",
        "WordNet is hierarchically organized for verbs differently, with the hypernym for run being travel. This is more specific than noun's top hypernym, which is entity. This means there is more distinction in actions and that they cannot be generalized as easy."
      ],
      "metadata": {
        "id": "9HL9LivmJwad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runverb = wn.synset('run.v.01')\n",
        "run = runverb.hypernyms()[0]\n",
        "top = wn.synset('travel.v.01')\n",
        "while run:\n",
        "    print(run)\n",
        "    if run == top:\n",
        "        break\n",
        "    if run.hypernyms():\n",
        "        run = run.hypernyms()[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x62dNNjuKsoi",
        "outputId": "91e83ec3-845e-4371-84b5-f51de862ee43"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('travel_rapidly.v.01')\n",
            "Synset('travel.v.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will output the **hypernyms**, **hyponyms**, **meronyms**,\n",
        "**holonyms**, and **antonyms**. Looks like run's hypernym is travel rapidy, and has many hyponyms. This makes sense since there are many other words that are similar to the verb run."
      ],
      "metadata": {
        "id": "6o31b--GM9x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('hypernyms: ', runverb.hypernyms())\n",
        "print('hyponyms: ', runverb.hyponyms())\n",
        "print('meronyms: ', runverb.part_meronyms())\n",
        "print('holonyms: ', runverb.part_holonyms())\n",
        "print('antonyms: ', runverb.lemmas()[0].antonyms())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8CPIE4xLdGz",
        "outputId": "fea808e7-c18f-46e1-edaf-75c66c1a0938"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypernyms:  [Synset('travel_rapidly.v.01')]\n",
            "hyponyms:  [Synset('hare.v.01'), Synset('jog.v.03'), Synset('lope.v.01'), Synset('outrun.v.01'), Synset('romp.v.02'), Synset('run.v.33'), Synset('run_bases.v.01'), Synset('rush.v.05'), Synset('scurry.v.01'), Synset('sprint.v.01'), Synset('streak.v.02'), Synset('trot.v.01')]\n",
            "meronyms:  []\n",
            "holonyms:  []\n",
            "antonyms:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will find as many forms of the verb 'run' as we can. To do this, we use the morphy function."
      ],
      "metadata": {
        "id": "WxljFtA-QrJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.morphy('running', pos = 'v'))\n",
        "print(wn.morphy('ran', pos = 'v'))\n",
        "print(wn.morphy('run', pos = 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diU9Z0DaRrRQ",
        "outputId": "c4d7f19e-f146-4398-dc6f-aa0bee6808a9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will select two words that are maybe similar: for this task we will select \"boat\" and \"yacht\".\n",
        "\n",
        "We will also run the Wu-Palmer similarity metric and the Lesk algorithm.\n",
        "\n",
        "The Wu-Palmer similarity metric is based on the common specific ancenstor node.\n"
      ],
      "metadata": {
        "id": "ffps-tC-UeLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pond = wn.synset('pond.n.01')\n",
        "lake = wn.synset('lake.n.01')\n",
        "print('Path Similarity: ', pond.path_similarity(lake))\n",
        "print('Wu-Palmer similarity: ', wn.wup_similarity(pond, lake))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrSKmnX1U2Nj",
        "outputId": "acfd1280-2616-4bfd-aa6c-5ccc35f43fc8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path Similarity:  0.5\n",
            "Wu-Palmer similarity:  0.9090909090909091\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that pond and lake are 50% similar, according to path_similarity.\n",
        "\n",
        "The Lesk algorithm returns the synset with the highest number of overlapping words between the context sentence and each synsets definition in the target word. In this case, the lesk algorithm correctly tags lake since water and body is there. This isn't always accurate though, especially for smaller bodies of text. It also makes sense that lake and pond are similar, as their hypernyms will both lead to water. That's why the Wu-Palmer similairty index scores it really high."
      ],
      "metadata": {
        "id": "3r8NWKHwVFiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "# look at the definitions for 'bank'\n",
        "for ss in wn.synsets('lake'):\n",
        "    print(ss, ss.definition())\n",
        "\n",
        "sent = ['Lets', 'jump', 'in', 'the', 'body', 'of', 'water', ',', 'the', 'lake', '!']\n",
        "print('n', lesk(sent, 'lake'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFvlKyFwWHor",
        "outputId": "9191236f-b20e-4a08-d00b-c011c46777f1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('lake.n.01') a body of (usually fresh) water surrounded by land\n",
            "Synset('lake.n.02') a purplish red pigment prepared from lac or cochineal\n",
            "Synset('lake.n.03') any of numerous bright translucent organic pigments\n",
            "n Synset('lake.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SentiWordNet**\n",
        "\n",
        "Next, we will explore SentiWordNet. This assigns three semantic scores for a given sysnet: positivity, negativity, and objectivity. These are assigned from a score of 0.0 to 1.0.\n",
        "\n",
        "We will use an emotionally charged word to explore the applications of SentiWordNet... Let's use 'shame'. As expected, shame is used mostly in a negative connotation. The last verb is slightly positive, which is interesting."
      ],
      "metadata": {
        "id": "5aeqLVWHdGjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(wn.synsets('shame'))\n",
        "shamenoun1 = swn.senti_synset('shame.n.01')\n",
        "print(shamenoun1)\n",
        "\n",
        "print(\"Positive score = \", shamenoun1.pos_score())\n",
        "print(\"Negative score = \", shamenoun1.neg_score())\n",
        "print( \"Objective score = \", shamenoun1.obj_score(), '\\n')\n",
        "\n",
        "senti_list = list(swn.senti_synsets('shame')) \n",
        "for item in senti_list:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugDZ8LgRevOq",
        "outputId": "38849663-47b6-4d3c-d526-aaa129cd625d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('shame.n.01'), Synset('shame.n.02'), Synset('pity.n.02'), Synset('dishonor.v.01'), Synset('shame.v.02'), Synset('shame.v.03'), Synset('shame.v.04')]\n",
            "<shame.n.01: PosScore=0.0 NegScore=0.75>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.75\n",
            "Objective score =  0.25 \n",
            "\n",
            "<shame.n.01: PosScore=0.0 NegScore=0.75>\n",
            "<shame.n.02: PosScore=0.0 NegScore=0.5>\n",
            "<pity.n.02: PosScore=0.0 NegScore=0.625>\n",
            "<dishonor.v.01: PosScore=0.0 NegScore=0.625>\n",
            "<shame.v.02: PosScore=0.0 NegScore=0.5>\n",
            "<shame.v.03: PosScore=0.0 NegScore=0.375>\n",
            "<shame.v.04: PosScore=0.125 NegScore=0.125>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to make up a sentence and see it's polarity, also for each word...\n",
        "\n",
        "'Keep going, you did a good job!'\n",
        "\n",
        "We see that the positive count is 0.5... Where does this come from?\n",
        "\n",
        "We can see that it all comes from job, which makes sense. If we switch out good, the semantics of the sentence changes completely. This is a good tool to use to determine if sentences lean positive or negative. If a sentence has overwhelmingly positive/negative polarity, then it can be used in various ways; for example, a chatbot can respond to negative or positive words differently."
      ],
      "metadata": {
        "id": "e4MN-vz4f947"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'Keep going, you did a good job!'\n",
        "neg = 0\n",
        "pos = 0\n",
        "tokens = sent.split()\n",
        "for token in tokens:\n",
        "    syn_list = list(swn.senti_synsets(token))\n",
        "    if syn_list:\n",
        "        syn = syn_list[0]\n",
        "        neg += syn.neg_score()\n",
        "        pos += syn.pos_score()\n",
        "    \n",
        "print(\"neg\\tpos counts\")\n",
        "print(neg, '\\t', pos)\n",
        "\n",
        "print('Score for keep: ')\n",
        "p = list(swn.senti_synsets('keep'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')\n",
        "\n",
        "print('Score for going: ')\n",
        "p = list(swn.senti_synsets('going'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')\n",
        "\n",
        "print('Score for did: ')\n",
        "p = list(swn.senti_synsets('did'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')\n",
        "\n",
        "\n",
        "print('Score for a: ')\n",
        "p = list(swn.senti_synsets('a'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')\n",
        "\n",
        "\n",
        "print('Score for good: ')\n",
        "p = list(swn.senti_synsets('good'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')\n",
        "\n",
        "\n",
        "print('Score for job: ')\n",
        "p = list(swn.senti_synsets('job'))[0]\n",
        "print(\"negative: \", p.neg_score())\n",
        "print(\"positive: \", p.pos_score())\n",
        "print(\"objective: \", p.obj_score(), '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdhhRiLggELQ",
        "outputId": "39a43899-ee4c-495c-d54d-21a488078293"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neg\tpos counts\n",
            "0.0 \t 0.5\n",
            "Score for keep: \n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0 \n",
            "\n",
            "Score for going: \n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0 \n",
            "\n",
            "Score for did: \n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0 \n",
            "\n",
            "Score for a: \n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0 \n",
            "\n",
            "Score for good: \n",
            "negative:  0.0\n",
            "positive:  0.5\n",
            "objective:  0.5 \n",
            "\n",
            "Score for job: \n",
            "negative:  0.0\n",
            "positive:  0.0\n",
            "objective:  1.0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, let's explore collocations. Collocations are words that have greater means when put together. They are also more likely to be combined because of association, for example, 'fast food' combines to have a whole new meaning.\n",
        "\n",
        "We will output collocations for text4, the Inaugural corpus."
      ],
      "metadata": {
        "id": "1e_rvKWsh3Ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.book import *\n",
        "text4\n",
        "\n",
        "print(text4.collocations())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvmW5NNgikWc",
        "outputId": "8a512fb3-0c5d-421f-acca-02c83ba72f27"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's select 'foreign nations' and calculate the mutual information."
      ],
      "metadata": {
        "id": "ywDjBupJjwwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text4.tokens)\n",
        "text[:50]\n",
        "\n",
        "import math\n",
        "vocab = len(set(text4))\n",
        "hg = text.count('foreign nations')/vocab\n",
        "print(\"p(foreign nations) = \",hg )\n",
        "h = text.count('foreign')/vocab\n",
        "print(\"p(foreign) = \", h)\n",
        "g = text.count('nations')/vocab\n",
        "print('p(nations) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)\n",
        "\n",
        "\n",
        "vocab = len(set(text4))\n",
        "hg = text.count('and I')/vocab\n",
        "print(\"p(and I) = \",hg )\n",
        "h = text.count('and')/vocab\n",
        "print(\"p(and) = \", h)\n",
        "g = text.count('I')/vocab\n",
        "print('p(I) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_lMJa4kF7X",
        "outputId": "e8c4ec3f-9951-4bdd-b3bb-20deb4c853de"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(foreign nations) =  0.0014962593516209476\n",
            "p(foreign) =  0.01027431421446384\n",
            "p(nations) =  0.020448877805486283\n",
            "pmi =  2.8322245851494996\n",
            "p(and I) =  0.004788029925187032\n",
            "p(and) =  0.5833416458852868\n",
            "p(I) =  0.16987531172069825\n",
            "pmi =  -4.371313198680179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 2.8 pmi indicates this is more likely to be a collocation, as it is positive and is more than the 'as I', which is not a collocation. The higher the pmi that is calculate through correlation and the log of probability from the vocab, the greater chance the two words form a meaning that is beyond its parts."
      ],
      "metadata": {
        "id": "hQSh8UXJkhZr"
      }
    }
  ]
}